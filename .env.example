# Ralph Ollama Configuration

# Ollama model to use (e.g., llama3.1, qwen2.5, mistral, etc.)
# Must be a tool-capable model for full functionality
RALPH_MODEL=llama3.1

# Ollama host URL - set to your remote host or keep localhost
# Examples:
#   Local: http://localhost:11434
#   Remote: http://your-server-ip:11434
#   Remote: https://ollama.example.com
OLLAMA_HOST=http://localhost:11434

# Maximum tool steps per iteration (safety cap)
RALPH_MAX_TOOL_STEPS=50
